{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nUsing TorchScript to serialize and deploy model\n===============================================\n\nModels in TorchANI's model zoo support TorchScript. TorchScript is a way to create\nserializable and optimizable models from PyTorch code. It allows users to saved their\nmodels from a Python process and loaded in a process where there is no Python dependency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin with, let's first import the modules we will use:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchani\nfrom typing import Tuple, Optional\nfrom torch import Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scripting builtin model directly\n--------------------------------\n\nLet's now load the built-in ANI-1ccx models. The builtin ANI-1ccx contains 8\nmodels trained with diffrent initialization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = torchani.models.ANI1ccx(periodic_table_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is very easy to compile and save the model using `torch.jit`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "compiled_model = torch.jit.script(model)\ntorch.jit.save(compiled_model, 'compiled_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Besides compiling the ensemble, it is also possible to compile a single network\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "compiled_model0 = torch.jit.script(model[0])\ntorch.jit.save(compiled_model0, 'compiled_model0.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For testing purposes, we will now load the models we just saved and see if they\nproduces the same output as the original model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loaded_compiled_model = torch.jit.load('compiled_model.pt')\nloaded_compiled_model0 = torch.jit.load('compiled_model0.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the molecule below to test:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coordinates = torch.tensor([[[0.03192167, 0.00638559, 0.01301679],\n                             [-0.83140486, 0.39370209, -0.26395324],\n                             [-0.66518241, -0.84461308, 0.20759389],\n                             [0.45554739, 0.54289633, 0.81170881],\n                             [0.66091919, -0.16799635, -0.91037834]]])\n# In periodic table, C = 6 and H = 1\nspecies = torch.tensor([[6, 1, 1, 1, 1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And here is the result:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energies_ensemble = model((species, coordinates)).energies\nenergies_single = model[0]((species, coordinates)).energies\nenergies_ensemble_jit = loaded_compiled_model((species, coordinates)).energies\nenergies_single_jit = loaded_compiled_model0((species, coordinates)).energies\nprint('Ensemble energy, eager mode vs loaded jit:', energies_ensemble.item(), energies_ensemble_jit.item())\nprint('Single network energy, eager mode vs loaded jit:', energies_single.item(), energies_single_jit.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Customize the model and script\n------------------------------\n\nYou could also customize the model you want to export. For example, let's do\nthe following customization to the model:\n\n- uses double as dtype instead of float\n- don't care about periodic boundary condition\n- in addition to energies, allow returnsing optionally forces, and hessians\n- when indexing atom species, use its index in the periodic table instead of 0, 1, 2, 3, ...\n\nyou could do the following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CustomModule(torch.nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.model = torchani.models.ANI1x(periodic_table_index=True).double()\n        # self.model = torchani.models.ANI1x(periodic_table_index=True)[0].double()\n        # self.model = torchani.models.ANI1ccx(periodic_table_index=True).double()\n\n    def forward(self, species: Tensor, coordinates: Tensor, return_forces: bool = False,\n                return_hessians: bool = False) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n        if return_forces or return_hessians:\n            coordinates.requires_grad_(True)\n\n        energies = self.model((species, coordinates)).energies\n\n        forces: Optional[Tensor] = None  # noqa: E701\n        hessians: Optional[Tensor] = None\n        if return_forces or return_hessians:\n            grad = torch.autograd.grad([energies.sum()], [coordinates], create_graph=return_hessians)[0]\n            assert grad is not None\n            forces = -grad\n            if return_hessians:\n                hessians = torchani.utils.hessian(coordinates, forces=forces)\n        return energies, forces, hessians\n\n\ncustom_model = CustomModule()\ncompiled_custom_model = torch.jit.script(custom_model)\ntorch.jit.save(compiled_custom_model, 'compiled_custom_model.pt')\nloaded_compiled_custom_model = torch.jit.load('compiled_custom_model.pt')\nenergies, forces, hessians = custom_model(species, coordinates, True, True)\nenergies_jit, forces_jit, hessians_jit = loaded_compiled_custom_model(species, coordinates, True, True)\n\nprint('Energy, eager mode vs loaded jit:', energies.item(), energies_jit.item())\nprint()\nprint('Force, eager mode vs loaded jit:\\n', forces.squeeze(0), '\\n', forces_jit.squeeze(0))\nprint()\ntorch.set_printoptions(sci_mode=False, linewidth=1000)\nprint('Hessian, eager mode vs loaded jit:\\n', hessians.squeeze(0), '\\n', hessians_jit.squeeze(0))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}