<!DOCTYPE html>
<html class="writer-html4" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Train Neural Network Potential From NeuroChem Input File &mdash; TorchANI 2.2.3.dev2+g3dfbaf4 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TorchANI" href="../api.html" />
    <link rel="prev" title="Train Neural Network Potential To Both Energies and Forces" href="nnp_training_force.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> TorchANI
          </a>
              <div class="version">
                2.2.3.dev2+g3dfbaf4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../start.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tips.html">Tips</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="energy_force.html">Computing Energy and Force Using Models Inside Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="ase_interface.html">Structure minimization and constant temperature MD using ASE interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Using TorchScript to serialize and deploy model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vibration_analysis.html">Computing Vibrational Frequencies Using Analytical Hessian</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_from_neurochem.html">Construct Model From NeuroChem Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnp_training.html">Train Your Own Neural Network Potential</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnp_training_force.html">Train Neural Network Potential To Both Energies and Forces</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Train Neural Network Potential From NeuroChem Input File</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TorchANI's API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">TorchANI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.models">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.data">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.utils">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.neurochem">NeuroChem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.ase">ASE Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.units">Units</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TorchANI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Train Neural Network Potential From NeuroChem Input File</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/neurochem_trainer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-examples-neurochem-trainer-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="train-neural-network-potential-from-neurochem-input-file">
<span id="neurochem-training"></span><span id="sphx-glr-examples-neurochem-trainer-py"></span><h1>Train Neural Network Potential From NeuroChem Input File<a class="headerlink" href="#train-neural-network-potential-from-neurochem-input-file" title="Permalink to this headline">¶</a></h1>
<p>This example shows how to use TorchANI’s NeuroChem trainer to read and run
NeuroChem’s training config file to train a neural network potential.</p>
<p>To begin with, let’s first import the modules we will use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchani</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
</pre></div>
</div>
<p>Now let’s setup path for the dataset and NeuroChem input file. Note that
these paths assumes the user run this script under the <code class="docutils literal notranslate"><span class="pre">examples</span></code> directory
of TorchANI’s repository. If you download this script, you should manually
set the path of these files in your system before this script can run
successfully. Also note that here for our demo purpose, we set both training
set and validation set the <code class="docutils literal notranslate"><span class="pre">ani_gdb_s01.h5</span></code> in TorchANI’s repository. This
allows this program to finish very quick, because that dataset is very small.
But this is wrong and should be avoided for any serious training.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="os.path.dirname" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.realpath" title="os.path.realpath" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span></a><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.html#os.getcwd" title="os.getcwd" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cfg_path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">path</span></a><span class="p">,</span> <span class="s1">&#39;../tests/test_data/inputtrain.ipt&#39;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">training_path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">path</span></a><span class="p">,</span> <span class="s1">&#39;../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5&#39;</span><span class="p">)</span>  <span class="c1"># noqa: E501</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">validation_path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">path</span></a><span class="p">,</span> <span class="s1">&#39;../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5&#39;</span><span class="p">)</span>  <span class="c1"># noqa: E501</span>
</pre></div>
</div>
<p>We also need to set the device to run the training:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device_str</span></a> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <a href="https://pytorch.org/docs/master/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device_str</span></a><span class="p">)</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">neurochem</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cfg_path</span></a><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;runs&#39;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">training_path</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">validation_path</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>=&gt; loading /home/runner/work/torchani/torchani/examples/../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5, total molecules: 1

1/1  [==============================] - 0.0s

2/1  [============================================================] - 0.0s
3/1  [==========================================================================================] - 0.1s=&gt; loading /home/runner/work/torchani/torchani/examples/../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5, total molecules: 1

1/1  [==============================] - 0.0s

2/1  [============================================================] - 0.0s
3/1  [==========================================================================================] - 0.0s
</pre></div>
</div>
<p>Once everything is set up, running NeuroChem is very easy. We simplify need a
<code class="docutils literal notranslate"><span class="pre">trainer.run()</span></code>. But here, in order for sphinx-gallery to be able to
capture the output of tqdm, let’s do some hacking first to make tqdm to print
its progressbar to stdout.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_tqdm</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><a href="https://docs.python.org/3/library/io.html#io.TextIOWrapper" title="io.TextIOWrapper" class="sphx-glr-backref-module-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span></a><span class="p">)</span>


<span class="n">trainer</span><span class="o">.</span><span class="n">tqdm</span> <span class="o">=</span> <span class="n">my_tqdm</span>
</pre></div>
</div>
<p>Now, let’s go!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/torchani-2.2.3.dev2+g3dfbaf4-py3.8.egg/torchani/aev.py:249: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the &#39;trunc&#39; function NOT &#39;floor&#39;). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode=&#39;trunc&#39;), or for actual floor division, use torch.div(a, b, rounding_mode=&#39;floor&#39;).
  pair_sizes = counts * (counts - 1) // 2

epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 1:  20%|##        | 1/5 [00:00&lt;00:00,  5.30it/s]
epoch 1:  40%|####      | 2/5 [00:00&lt;00:00,  5.31it/s]
epoch 1:  60%|######    | 3/5 [00:00&lt;00:00,  5.33it/s]
epoch 1:  80%|########  | 4/5 [00:00&lt;00:00,  5.31it/s]
epoch 1: 100%|##########| 5/5 [00:00&lt;00:00,  6.22it/s]

epoch 2:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 2:  20%|##        | 1/5 [00:00&lt;00:00,  5.09it/s]
epoch 2:  40%|####      | 2/5 [00:00&lt;00:00,  5.23it/s]
epoch 2:  60%|######    | 3/5 [00:00&lt;00:00,  5.26it/s]
epoch 2:  80%|########  | 4/5 [00:00&lt;00:00,  5.22it/s]
epoch 2: 100%|##########| 5/5 [00:00&lt;00:00,  6.11it/s]

epoch 3:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 3:  20%|##        | 1/5 [00:00&lt;00:00,  5.31it/s]
epoch 3:  40%|####      | 2/5 [00:00&lt;00:00,  5.35it/s]
epoch 3:  60%|######    | 3/5 [00:00&lt;00:00,  5.26it/s]
epoch 3:  80%|########  | 4/5 [00:00&lt;00:00,  5.18it/s]
epoch 3: 100%|##########| 5/5 [00:00&lt;00:00,  6.11it/s]

epoch 4:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 4:  20%|##        | 1/5 [00:00&lt;00:00,  5.18it/s]
epoch 4:  40%|####      | 2/5 [00:00&lt;00:00,  5.19it/s]
epoch 4:  60%|######    | 3/5 [00:00&lt;00:00,  5.13it/s]
epoch 4:  80%|########  | 4/5 [00:00&lt;00:00,  5.15it/s]
epoch 4: 100%|##########| 5/5 [00:00&lt;00:00,  6.04it/s]

epoch 5:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 5:  20%|##        | 1/5 [00:00&lt;00:00,  5.11it/s]
epoch 5:  40%|####      | 2/5 [00:00&lt;00:00,  5.24it/s]
epoch 5:  60%|######    | 3/5 [00:00&lt;00:00,  5.26it/s]
epoch 5:  80%|########  | 4/5 [00:00&lt;00:00,  5.20it/s]
epoch 5: 100%|##########| 5/5 [00:00&lt;00:00,  6.09it/s]

epoch 6:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 6:  20%|##        | 1/5 [00:00&lt;00:00,  4.95it/s]
epoch 6:  40%|####      | 2/5 [00:00&lt;00:00,  5.00it/s]
epoch 6:  60%|######    | 3/5 [00:00&lt;00:00,  4.97it/s]
epoch 6:  80%|########  | 4/5 [00:00&lt;00:00,  4.97it/s]
epoch 6: 100%|##########| 5/5 [00:00&lt;00:00,  5.84it/s]

epoch 7:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 7:  20%|##        | 1/5 [00:00&lt;00:00,  5.01it/s]
epoch 7:  40%|####      | 2/5 [00:00&lt;00:00,  5.12it/s]
epoch 7:  60%|######    | 3/5 [00:00&lt;00:00,  5.15it/s]
epoch 7:  80%|########  | 4/5 [00:00&lt;00:00,  5.17it/s]
epoch 7: 100%|##########| 5/5 [00:00&lt;00:00,  6.04it/s]
</pre></div>
</div>
<p>Alternatively, you can run NeuroChem trainer directly using command line.
There is no need for programming. Just run the following command for help
<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">torchani.neurochem.trainer</span> <span class="pre">-h</span></code> for usage. For this demo, the
equivalent command is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cmd</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;python&#39;</span><span class="p">,</span> <span class="s1">&#39;-m&#39;</span><span class="p">,</span> <span class="s1">&#39;torchani.neurochem.trainer&#39;</span><span class="p">,</span> <span class="s1">&#39;-d&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device_str</span></a><span class="p">,</span>
       <span class="s1">&#39;--tqdm&#39;</span><span class="p">,</span> <span class="s1">&#39;--tensorboard&#39;</span><span class="p">,</span> <span class="s1">&#39;runs&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cfg_path</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">training_path</span></a><span class="p">,</span>
       <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">validation_path</span></a><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cmd</span></a><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>python -m torchani.neurochem.trainer -d cpu --tqdm --tensorboard runs /home/runner/work/torchani/torchani/examples/../tests/test_data/inputtrain.ipt /home/runner/work/torchani/torchani/examples/../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5 /home/runner/work/torchani/torchani/examples/../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5
</pre></div>
</div>
<p>Now let’s invoke this command to see what we get. Again, we redirect stderr
to stdout simplify for sphinx-gallery to be able to capture it when
generating this document:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">subprocess</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen" title="subprocess.Popen" class="sphx-glr-backref-module-subprocess sphx-glr-backref-type-py-class"><span class="n">Popen</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">PIPE</span></a>  <span class="c1"># noqa: E402</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen" title="subprocess.Popen" class="sphx-glr-backref-module-subprocess sphx-glr-backref-type-py-class"><span class="n">Popen</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cmd</span></a><span class="p">,</span> <span class="n">stderr</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">PIPE</span></a><span class="p">)</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/torchani-2.2.3.dev2+g3dfbaf4-py3.8.egg/torchani/aev.py:16: UserWarning: cuaev not installed
  warnings.warn(&quot;cuaev not installed&quot;)
/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/torch/functional.py:1069: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.cartesian_prod(tensors)  # type: ignore[attr-defined]
/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/torchani-2.2.3.dev2+g3dfbaf4-py3.8.egg/torchani/aev.py:249: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the &#39;trunc&#39; function NOT &#39;floor&#39;). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode=&#39;trunc&#39;), or for actual floor division, use torch.div(a, b, rounding_mode=&#39;floor&#39;).
  pair_sizes = counts * (counts - 1) // 2

epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 1:  20%|██        | 1/5 [00:00&lt;00:00,  5.23it/s]
epoch 1:  40%|████      | 2/5 [00:00&lt;00:00,  5.26it/s]
epoch 1:  60%|██████    | 3/5 [00:00&lt;00:00,  5.21it/s]
epoch 1:  80%|████████  | 4/5 [00:00&lt;00:00,  5.17it/s]
epoch 1: 100%|██████████| 5/5 [00:00&lt;00:00,  6.10it/s]

epoch 2:   0%|          | 0/5 [00:00&lt;?, ?it/s]
epoch 2:  20%|██        | 1/5 [00:00&lt;00:00,  5.01it/s]
epoch 2:  40%|████      | 2/5 [00:00&lt;00:00,  5.13it/s]
epoch 2:  60%|██████    | 3/5 [00:00&lt;00:00,  5.13it/s]
epoch 2:  80%|████████  | 4/5 [00:00&lt;00:00,  5.13it/s]
epoch 2: 100%|██████████| 5/5 [00:00&lt;00:00,  6.00it/s]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  14.636 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-neurochem-trainer-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<a class="reference download internal" download="" href="../_downloads/cca758d34ccbb1f250032c04edfb280b/neurochem_trainer.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">neurochem_trainer.py</span></code></a></div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<a class="reference download internal" download="" href="../_downloads/5d13693ea1043e9fd13bfe1a44eafeb0/neurochem_trainer.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">neurochem_trainer.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="nnp_training_force.html" class="btn btn-neutral float-left" title="Train Neural Network Potential To Both Energies and Forces" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../api.html" class="btn btn-neutral float-right" title="TorchANI" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Roitberg Group.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>