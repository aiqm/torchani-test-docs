

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Train Your Own Neural Network Potential, Using PyTorch-Ignite &mdash; TorchANI 1.1.dev11+g452a74a documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Use Disk Cache of AEV to Boost Training" href="cache_aev.html" />
    <link rel="prev" title="Train Neural Network Potential To Both Energies and Forces" href="nnp_training_force.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> TorchANI
          

          
          </a>

          
            
            
              <div class="version">
                1.1.dev11+g452a74a
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../start.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="energy_force.html">Computing Energy and Force Using Models Inside Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="ase_interface.html">Structure minimization and constant temperature MD using ASE interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Using TorchScript to serialize and deploy model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vibration_analysis.html">Computing Vibrational Frequencies Using Analytical Hessian</a></li>
<li class="toctree-l1"><a class="reference internal" href="load_from_neurochem.html">Construct Model From NeuroChem Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnp_training.html">Train Your Own Neural Network Potential</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnp_training_force.html">Train Neural Network Potential To Both Energies and Forces</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Train Your Own Neural Network Potential, Using PyTorch-Ignite</a></li>
<li class="toctree-l1"><a class="reference internal" href="cache_aev.html">Use Disk Cache of AEV to Boost Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="neurochem_trainer.html">Train Neural Network Potential From NeuroChem Input File</a></li>
</ul>
<p class="caption"><span class="caption-text">TorchANI's API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">TorchANI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.models">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.data">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.utils">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.neurochem">NeuroChem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.ase">ASE Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.optim">TorchANI Optimizater</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html#module-torchani.ignite">Ignite Helpers</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TorchANI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Train Your Own Neural Network Potential, Using PyTorch-Ignite</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/examples/nnp_training_ignite.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-examples-nnp-training-ignite-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="train-your-own-neural-network-potential-using-pytorch-ignite">
<span id="training-example-ignite"></span><span id="sphx-glr-examples-nnp-training-ignite-py"></span><h1>Train Your Own Neural Network Potential, Using PyTorch-Ignite<a class="headerlink" href="#train-your-own-neural-network-potential-using-pytorch-ignite" title="Permalink to this headline">¶</a></h1>
<p>We have seen how to train a neural network potential by manually writing
training loop in <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a>. TorchANI provide tools to work
with PyTorch-Ignite to simplify the writing of training code. This tutorial
shows how to use these tools to train a demo model. The setup in this demo is
not necessarily identical to NeuroChem.</p>
<p>This tutorial assumes readers have read <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a>.</p>
<p>To begin with, let’s first import the modules and setup devices we will use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">ignite</span>
<span class="kn">import</span> <span class="nn">torchani</span>
<span class="kn">import</span> <span class="nn">timeit</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">ignite.contrib.handlers</span>
<span class="kn">import</span> <span class="nn">torch.utils.tensorboard</span>

<span class="c1"># device to run the training</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now let’s setup training hyperparameters and dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># training and validation set</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
<span class="n">dspath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;../dataset/ani1-up_to_gdb4/ani_gdb_s01.h5&#39;</span><span class="p">)</span>

<span class="c1"># checkpoint file to save model when validation RMSE improves</span>
<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s1">&#39;model.pt&#39;</span>

<span class="c1"># max epochs to run the training</span>
<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1"># Compute training RMSE every this steps. Since the training set is usually</span>
<span class="c1"># huge and the loss funcition does not directly gives us RMSE, we need to</span>
<span class="c1"># check the training RMSE to see overfitting.</span>
<span class="n">training_rmse_every</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># batch size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2560</span>

<span class="c1"># log directory for tensorboard</span>
<span class="n">log</span> <span class="o">=</span> <span class="s1">&#39;runs&#39;</span>
</pre></div>
</div>
<p>Instead of manually specifying hyperparameters as in <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a>,
here we will load them from files.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">const_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;../torchani/resources/ani-1x_8x/rHCNO-5.2R_16-3.5A_a4-8.params&#39;</span><span class="p">)</span>  <span class="c1"># noqa: E501</span>
<span class="n">consts</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">neurochem</span><span class="o">.</span><span class="n">Constants</span><span class="p">(</span><span class="n">const_file</span><span class="p">)</span>
<span class="n">aev_computer</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">AEVComputer</span><span class="p">(</span><span class="o">**</span><span class="n">consts</span><span class="p">)</span>
<span class="n">energy_shifter</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">EnergyShifter</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>Now let’s define atomic neural networks. Here in this demo, we use the same
size of neural network for all atom types, but this is not necessary.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">atomic</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="n">nn</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">ANIModel</span><span class="p">([</span><span class="n">atomic</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nn</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ANIModel(
  (module_list): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=384, out_features=128, bias=True)
      (1): CELU(alpha=0.1)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): CELU(alpha=0.1)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): CELU(alpha=0.1)
      (6): Linear(in_features=64, out_features=1, bias=True)
    )
    (1): Sequential(
      (0): Linear(in_features=384, out_features=128, bias=True)
      (1): CELU(alpha=0.1)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): CELU(alpha=0.1)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): CELU(alpha=0.1)
      (6): Linear(in_features=64, out_features=1, bias=True)
    )
    (2): Sequential(
      (0): Linear(in_features=384, out_features=128, bias=True)
      (1): CELU(alpha=0.1)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): CELU(alpha=0.1)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): CELU(alpha=0.1)
      (6): Linear(in_features=64, out_features=1, bias=True)
    )
    (3): Sequential(
      (0): Linear(in_features=384, out_features=128, bias=True)
      (1): CELU(alpha=0.1)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): CELU(alpha=0.1)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): CELU(alpha=0.1)
      (6): Linear(in_features=64, out_features=1, bias=True)
    )
  )
)
</pre></div>
</div>
<p>If checkpoint from previous training exists, then load it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">):</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">model_checkpoint</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s now create a pipeline of AEV Computer –&gt; Neural Networks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">aev_computer</span><span class="p">,</span> <span class="n">nn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Now setup tensorboard</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">writer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">tensorboard</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log</span><span class="p">)</span>
</pre></div>
</div>
<p>Now load training and validation datasets into memory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">training</span><span class="p">,</span> <span class="n">validation</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">load_ani_dataset</span><span class="p">(</span>
    <span class="n">dspath</span><span class="p">,</span> <span class="n">consts</span><span class="o">.</span><span class="n">species_to_tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">rm_outlier</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="p">[</span><span class="n">energy_shifter</span><span class="o">.</span><span class="n">subtract_from_dataset</span><span class="p">],</span> <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
<p>We have tools to deal with the chunking (see <a class="reference internal" href="nnp_training.html#training-example"><span class="std std-ref">Train Your Own Neural Network Potential</span></a>). These
tools can be used as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">container</span> <span class="o">=</span> <span class="n">torchani</span><span class="o">.</span><span class="n">ignite</span><span class="o">.</span><span class="n">Container</span><span class="p">({</span><span class="s1">&#39;energies&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">})</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">ignite</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">create_supervised_trainer</span><span class="p">(</span>
    <span class="n">container</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">torchani</span><span class="o">.</span><span class="n">ignite</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="s1">&#39;energies&#39;</span><span class="p">))</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">ignite</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">create_supervised_evaluator</span><span class="p">(</span>
    <span class="n">container</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="n">torchani</span><span class="o">.</span><span class="n">ignite</span><span class="o">.</span><span class="n">RMSEMetric</span><span class="p">(</span><span class="s1">&#39;energies&#39;</span><span class="p">)</span>
    <span class="p">})</span>
</pre></div>
</div>
<p>Let’s add a progress bar for the trainer</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">ignite</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">handlers</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
</pre></div>
</div>
<p>And some event handlers to compute validation and training metrics:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hartree2kcal</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">627.509</span> <span class="o">*</span> <span class="n">x</span>


<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">ignite</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_STARTED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">validation_and_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">evaluator</span> <span class="o">=</span> <span class="n">ignite</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">create_supervised_evaluator</span><span class="p">(</span>
            <span class="n">container</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">{</span>
                <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="n">torchani</span><span class="o">.</span><span class="n">ignite</span><span class="o">.</span><span class="n">RMSEMetric</span><span class="p">(</span><span class="s1">&#39;energies&#39;</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span>
        <span class="n">rmse</span> <span class="o">=</span> <span class="n">hartree2kcal</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;RMSE&#39;</span><span class="p">])</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">rmse</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">)</span>

    <span class="c1"># compute validation RMSE</span>
    <span class="n">evaluate</span><span class="p">(</span><span class="n">validation</span><span class="p">,</span> <span class="s1">&#39;validation_rmse_vs_epoch&#39;</span><span class="p">)</span>

    <span class="c1"># compute training RMSE</span>
    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span> <span class="o">%</span> <span class="n">training_rmse_every</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">evaluate</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="s1">&#39;training_rmse_vs_epoch&#39;</span><span class="p">)</span>

    <span class="c1"># checkpoint model</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">model_checkpoint</span><span class="p">)</span>
</pre></div>
</div>
<p>Also some to log elapsed time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="o">.</span><span class="n">default_timer</span><span class="p">()</span>


<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">ignite</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_STARTED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">log_time</span><span class="p">(</span><span class="n">trainer</span><span class="p">):</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timeit</span><span class="o">.</span><span class="n">default_timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;time_vs_epoch&#39;</span><span class="p">,</span> <span class="n">elapsed</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epoch</span><span class="p">)</span>
</pre></div>
</div>
<p>Also log the loss per iteration:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">ignite</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">log_loss</span><span class="p">(</span><span class="n">trainer</span><span class="p">):</span>
    <span class="n">iteration</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;loss_vs_iteration&#39;</span><span class="p">,</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>
</pre></div>
</div>
<p>And finally, we are ready to run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0/4]   0%|           [00:00&lt;?]
Epoch [1/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [1/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [1/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [1/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [1/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [1/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [1/20]: [4/4] 100%|########## [00:00&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [2/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [2/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [2/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [2/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [2/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [2/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [2/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [3/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [3/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [3/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [3/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [3/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [3/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [3/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [4/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [4/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [4/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [4/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [4/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [4/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [4/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [5/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [5/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [5/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [5/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [5/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [5/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [5/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [6/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [6/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [6/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [6/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [6/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [6/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [6/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [7/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [7/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [7/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [7/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [7/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [7/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [7/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [8/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [8/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [8/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [8/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [8/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [8/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [8/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [9/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [9/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [9/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [9/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [9/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [9/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [9/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [10/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [10/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [10/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [10/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [10/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [10/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [10/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [11/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [11/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [11/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [11/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [11/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [11/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [11/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [12/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [12/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [12/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [12/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [12/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [12/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [12/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [13/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [13/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [13/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [13/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [13/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [13/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [13/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [14/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [14/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [14/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [14/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [14/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [14/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [14/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [15/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [15/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [15/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [15/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [15/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [15/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [15/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [16/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [16/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [16/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [16/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [16/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [16/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [16/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [17/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [17/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [17/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [17/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [17/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [17/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [17/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [18/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [18/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [18/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [18/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [18/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [18/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [18/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [19/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [19/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [19/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [19/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [19/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [19/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [19/20]: [4/4] 100%|########## [00:01&lt;00:00]


[0/4]   0%|           [00:00&lt;?]
Epoch [20/20]: [0/4]   0%|           [00:00&lt;?]
Epoch [20/20]: [1/4]  25%|##5        [00:00&lt;00:01]
Epoch [20/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [20/20]: [2/4]  50%|#####      [00:00&lt;00:00]
Epoch [20/20]: [3/4]  75%|#######5   [00:00&lt;00:00]
Epoch [20/20]: [3/4]  75%|#######5   [00:01&lt;00:00]
Epoch [20/20]: [4/4] 100%|########## [00:01&lt;00:00]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  36.200 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-nnp-training-ignite-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/3a9df1868e6c8a659aa1599a39bef616/nnp_training_ignite.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">nnp_training_ignite.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/730f266a5729cdd9e3efd8f9194606ea/nnp_training_ignite.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">nnp_training_ignite.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="cache_aev.html" class="btn btn-neutral float-right" title="Use Disk Cache of AEV to Boost Training" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="nnp_training_force.html" class="btn btn-neutral float-left" title="Train Neural Network Potential To Both Energies and Forces" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Roitberg Group

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>